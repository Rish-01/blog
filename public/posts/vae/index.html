<!doctype html><html lang=en dir=auto><head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Variational Autoencoders and Maximum Likelihood Estimation | Rish's AI Notes</title>
<meta name=keywords content="ML Estimation,KL Divergence,Evidence Lower Bound,Variational Autoencoders"><meta name=description content="In my previous blog, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).
In this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:

Act as a generative model that mimics the data distribution that it was trained on.
Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on.

Preliminary Information
In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize."><meta name=author content="Rishab Sharma"><link rel=canonical href=http://localhost:1313/blog/posts/vae/><meta name=google-site-verification content="G-J9S4RERMVE"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/blog/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/blog/posts/vae/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-J9S4RERMVE"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-J9S4RERMVE")</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.css integrity=sha384-Htz9HMhiwV8GuQ28Xr9pEs1B4qJiYu/nYLLwlDklR53QibDfmQzi7rYxXhMH/5/u crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/katex.min.js integrity=sha384-bxmi2jLGCvnsEqMuYLKE/KsVCxV3PqmKeK6Y6+lmNXBry6+luFkEOsmp5vD9I/7+ crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.15/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload='renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}]})'></script><meta property="og:url" content="http://localhost:1313/blog/posts/vae/"><meta property="og:site_name" content="Rish's AI Notes"><meta property="og:title" content="Variational Autoencoders and Maximum Likelihood Estimation"><meta property="og:description" content="In my previous blog, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).
In this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:
Act as a generative model that mimics the data distribution that it was trained on. Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on. Preliminary Information In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-06T00:13:00+05:30"><meta property="article:modified_time" content="2025-03-06T00:13:00+05:30"><meta property="article:tag" content="ML Estimation"><meta property="article:tag" content="KL Divergence"><meta property="article:tag" content="Evidence Lower Bound"><meta property="article:tag" content="Variational Autoencoders"><meta property="og:image" content="http://localhost:1313/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Variational Autoencoders and Maximum Likelihood Estimation"><meta name=twitter:description content="In my previous blog, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).
In this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:

Act as a generative model that mimics the data distribution that it was trained on.
Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on.

Preliminary Information
In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/blog/posts/"},{"@type":"ListItem","position":2,"name":"Variational Autoencoders and Maximum Likelihood Estimation","item":"http://localhost:1313/blog/posts/vae/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Variational Autoencoders and Maximum Likelihood Estimation","name":"Variational Autoencoders and Maximum Likelihood Estimation","description":"In my previous blog, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).\nIn this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:\nAct as a generative model that mimics the data distribution that it was trained on. Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on. Preliminary Information In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize.\n","keywords":["ML Estimation","KL Divergence","Evidence Lower Bound","Variational Autoencoders"],"articleBody":"In my previous blog, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).\nIn this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:\nAct as a generative model that mimics the data distribution that it was trained on. Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on. Preliminary Information In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize.\nMonte Carlo Approximation Let us consider an expectation of a function $f(x)$ with respect to a probability distribution $p(x)$ where $x$ is our random variable.\n$$ \\mathbb{E}_{x \\sim p(x)} [f(x)] = \\int_{x} p(x) f(x) dx $$\nHowever, the above integral is intractable if $x$ is higher dimensional. Instead of computing the expectation exactly, we can approximate it using Monte Carlo sampling. If we draw $N$ independent samples $\\set{x_{1}, \\cdots, x_{N}} \\overset{\\text{i.i.d.}}{\\sim} p(x)$, then the Monte Carlo estimate of the expectation is:\n$$ \\mathbb{E}_{x \\sim p(x)} [f(x)] \\approx \\frac{1}{N} \\sum_{i=1}^N f(x_i) $$\nThis approximation becomes more accurate as the number of samples $N$ increases, following the law of large numbers.\nJensen’s Inequality I’ve taken a very crude proof for Jensen’s inequality from Deep Generative Models (Stanford). Let us consider the term $\\log \\mathbb{E}_{q(\\boldsymbol{z})}[f(\\boldsymbol{z})]$ and get this in terms of an expectation that is computable with sample averages (Monte-Carlo approximation). We also use the fact that $\\log$ is a concave function. From the definition of a concave function, we have the below result for any two points $x$ and $y$ in the domain of $\\log(\\cdot)$.\n$$ \\log(px + (1 - p)y) \u003e= p \\log(x) + (1 - p) \\log(y) \\quad \\forall p \\in [0, 1] \\tag{1} $$\nWe can now use the above result to derive Jensen’s inequality. The above result is generalizable to any convex combination of more than two points.\n$$ \\begin{align*} \\log \\mathbb{E}_{q(\\boldsymbol{z})}[f(\\boldsymbol{z})] \u0026= \\log(\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z})f(\\boldsymbol{z})) \\\\ \u0026\u003e= (\\sum_{\\boldsymbol{z}} q(\\boldsymbol{z}) \\log f(\\boldsymbol{z})) \\quad (\\text{from eq. (1)}) \\\\ \u0026= \\mathbb{E}_{q(\\boldsymbol{z})}[\\log f(\\boldsymbol{z})] \\end{align*} $$\nGaussian Reparametrization Let’s say we want to sample from a Gaussian distribution $z \\sim \\mathcal{N}(\\mu, \\sigma^{2})$. Instead of directly sampling from our Gaussian with an arbitrary mean and variance, we can instead sample from a standard normal distribution $\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, 1)$ and use a deterministic transformation.\n$$ z = \\mu + \\sigma \\cdot \\boldsymbol{\\epsilon}, \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0,1) $$\nIt turns out that using the reparametrization trick makes the gradient of our loss function tractable in a VAE.\nFormalizing the Optimization Problem Consider a dataset of $ m $ images $ \\mathbb{X} = \\{\\mathbf{x^{(1)}}, \\dots, \\mathbf{x^{(m)}}\\} $ where $ \\mathbf{x^{(i)}} \\in \\mathbb{R}^{n \\times n} $ is drawn independently (i.i.d) from the true but unknown data generating distribution $ p_{\\text{data}}(\\boldsymbol{x}) $. Our main goal is to model this distribution using $p_{\\theta}(\\boldsymbol{x})$ and learn it using data samples.\nRecalling our section on KL-Divergence, our objective can be summarized as:\n$$ L(\\theta) = \\arg\\min_\\theta D_{KL}(p_{\\text{data}}||p_{\\theta}) $$\nWe further recall from our previous blog – the connection between minimizing KL-Divergence and maximizing the likelihood. Our optimization problem then converts to maximizing the log-likelihood.\n$$ \\begin{align*} L(\\theta) \u0026= \\arg\\min_\\theta \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\boldsymbol{x})} \\left[ \\log \\frac{p_{\\text{data}}(\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{x})} \\right] \\\\ \u0026= \\arg\\min_\\theta \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\boldsymbol{x})} \\left[ \\log p_{\\text{data}}(\\boldsymbol{x}) - \\log p_{\\theta}(\\boldsymbol{x}) \\right] \\\\ \u0026= \\arg\\min_\\theta \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\boldsymbol{x})} \\left[ \\log p_{\\text{data}}(\\boldsymbol{x}) \\right] - \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}} \\left[ \\log p_{\\theta}(\\boldsymbol{x}) \\right] \\\\ \u0026= \\arg\\max_\\theta \\mathbb{E}_{\\mathbf{x} \\sim p_{\\text{data}}(\\boldsymbol{x})} \\left[ \\log p_{\\theta}(\\boldsymbol{x}) \\right] \\quad (\\because \\text{First term is independent of } \\theta) \\\\ \u0026= \\arg\\max_\\theta \\frac{1}{N} \\sum_{i=1}^N \\log p_{\\theta}(x_i) \\quad (\\text{Monte-Carlo estimation}) \\end{align*} $$\nDeriving the Evidence Lower Bound (ELBO) Let us consider the term $p_{\\theta}(\\boldsymbol{x})$. Since $p_{\\theta}(\\boldsymbol{x})$ is a latent variable model, it can be written as,\n$$ p_{\\theta}(\\boldsymbol{x}) = \\int p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}) d\\boldsymbol{z} \\tag{2} $$\nThe above equation is just the marginalization of the joint distribution $p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})$. We are interested in computing $\\log p_{\\theta}(\\boldsymbol{x})$. Our main goal is to write the log-likelihood function in terms of an expectation which is computable.\n$$ \\begin{align*} \\log p_{\\theta}(\\boldsymbol{x}) \u0026= \\log \\int_{\\boldsymbol{z}} p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z}) d\\boldsymbol{z} \\\\ \u0026= \\log \\int_{\\boldsymbol{z}} \\frac{p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z} | \\boldsymbol{x})} q(\\boldsymbol{z}|\\boldsymbol{x}) d\\boldsymbol{z} \\\\ \u0026= \\log \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[ \\frac{p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z}|\\boldsymbol{x})} \\right] \\\\ \u0026\u003e= \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z}|\\boldsymbol{x})} \\right] \\quad (\\text{From Jensen’s inequality}) \\\\ \u0026= \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x}|\\boldsymbol{z}) p_{\\theta}(\\boldsymbol{z})}{q(\\boldsymbol{z} |\\boldsymbol{x})} \\right] \\\\ \u0026= \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log p_{\\theta}(\\boldsymbol{x}|\\boldsymbol{z}) \\right] - \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{q(\\boldsymbol{z}|\\boldsymbol{x})}{p_{\\theta}(\\boldsymbol{z})} \\right] \\\\ \u0026= \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log p_{\\theta}(\\boldsymbol{x}|\\boldsymbol{z}) \\right] - D_{KL}(q(\\boldsymbol{z}|\\boldsymbol{x}) || p_{\\theta}(\\boldsymbol{z})) \\\\ \u0026:= F_{\\theta}(q) \\end{align*} $$\nWe have derived a tractable lower bound $F_{\\theta}(q)$ (ELBO) for log-likelihood that we can maximize. The tightness of this lower bound depends on the choice of $q(\\boldsymbol{z}|\\boldsymbol{x})$ (variational posterior).\nAnalysis on the Variational Posterior $q(\\boldsymbol{z}|\\boldsymbol{x})$ and Tightness of Lower Bound Let us consider the term $(\\log p_{\\theta}(\\boldsymbol{x}) - F_{\\theta}(q))$. To have a tight lower bound, we need to choose a $q$ that minimizes this difference.\n$$ \\begin{align*} \\log p_{\\theta}(\\boldsymbol{x}) - F_{\\theta}(q) \u0026= \\log p_{\\theta}(\\boldsymbol{x}) - \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})}{q(\\boldsymbol{z}|\\boldsymbol{x})} \\right] \\\\ \u0026= \\log p_{\\theta}(\\boldsymbol{x}) - \\mathbb{E}_{q(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x}) p_{\\theta}(\\boldsymbol{x})}{q(\\boldsymbol{z} |\\boldsymbol{x})} \\right] \\\\ \u0026= \\log p_{\\theta}(\\boldsymbol{x}) - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x}) p_{\\theta}(\\boldsymbol{x})}{q(\\boldsymbol{z} |\\boldsymbol{x})} \\right) d\\boldsymbol{z} \\\\ \u0026= \\log p_{\\theta}(\\boldsymbol{x}) - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log p_{\\theta}(\\boldsymbol{x}) d\\boldsymbol{z} - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})}{{q(\\boldsymbol{z} |\\boldsymbol{x})}} \\right) d\\boldsymbol{z} \\\\ \u0026= \\log p_{\\theta}(\\boldsymbol{x}) - \\log p_{\\theta}(\\boldsymbol{x}) \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) d\\boldsymbol{z} - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})}{{q(\\boldsymbol{z} |\\boldsymbol{x})}} \\right) d\\boldsymbol{z} \\\\ \u0026= \\cancel{\\log p_{\\theta}(\\boldsymbol{x})} - \\cancel{\\log p_{\\theta}(\\boldsymbol{x})} - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})}{{q(\\boldsymbol{z} |\\boldsymbol{x})}} \\right) d\\boldsymbol{z} \\quad (\\because \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) d\\boldsymbol{z} = 1)\\\\ \u0026= - \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})}{{q(\\boldsymbol{z} |\\boldsymbol{x})}} \\right) d\\boldsymbol{z} \\\\ \u0026= \\int_{\\boldsymbol{z}} q(\\boldsymbol{z} |\\boldsymbol{x}) \\log \\left(\\frac{{q(\\boldsymbol{z} |\\boldsymbol{x})}}{p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})} \\right) d\\boldsymbol{z} \\\\ \u0026= D_{KL}(q(\\boldsymbol{z} |\\boldsymbol{x}) || p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})) \\end{align*} $$\nWe have therefore proved that the error from the lower bound is,\n$$ \\log p_{\\theta}(\\boldsymbol{x}) - F_{\\theta}(q) = D_{KL}(q(\\boldsymbol{z} |\\boldsymbol{x}) || p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})) $$\nWe can find the optimal value for $q(\\boldsymbol{z} |\\boldsymbol{x})$ by setting this error to zero.\n$$ D_{KL}(q(\\boldsymbol{z} |\\boldsymbol{x}) || p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})) = 0 $$\nTherefore, the optimal value of $q(\\boldsymbol{z} |\\boldsymbol{x})$ is $p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$ where the lower bound is known to be the tightest. However, $p_{\\theta}(\\boldsymbol{z}|\\boldsymbol{x})$ is not tractable in VAEs which is why we explore alternate forms for $q(\\boldsymbol{z} |\\boldsymbol{x})$.\nModeling VAE using Neural Networks Fig 1. Variational Autoencoder\nIn a VAE, $q(\\boldsymbol{z}|\\boldsymbol{x})$ is modeled using a stochastic neural network with parameters $\\phi$. We assume a Gaussian form for $q(\\boldsymbol{z}|\\boldsymbol{x})$ for mathematical convenience. Therefore, the encoder can be used to predict the parameters of our Gaussian distribution.\n$$ q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}(z; \\mu_{\\phi}(\\boldsymbol{x}), \\Sigma_{\\phi}(\\boldsymbol{x})) $$\nWe also assume a diagonal form for the covariance matrix $\\Sigma_{\\phi}(\\boldsymbol{x}) = diag(\\sigma_{1}, \\cdots, \\sigma_{k})$ for further convenience.\n$$ \\therefore q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}(z; \\mu_{\\phi}(\\boldsymbol{x}), diag(\\sigma_{1}, \\cdots, \\sigma_{k})) $$\nHere, our latent variable $\\boldsymbol{z} \\in \\mathbb{R}^k$ and $D = \\set{\\boldsymbol{x_i}}_{i=1}^n \\sim p_{\\text{data}}$ where $x_i \\in \\mathbb{R}^d \\quad \\forall i \\in \\set{1, \\cdots, n}$. Since our latent variable is $k$-dimensional, $\\mu(\\boldsymbol{x}) \\in \\mathbb{R}^k$, and $ [\\sigma_1, \\cdots, \\sigma_k]^\\top \\in \\mathbb{R}^k $. Our encoder therefore maps our input to $\\mathbb{R}^{2k}$ dimensional space to estimate the parameters of our Gaussian distribution, $\\mu(\\boldsymbol{x})$, and $diag(\\sigma_1, \\cdots, \\sigma_k)$.\nComputing the Gradient of the ELBO for Training Let us go back to the ELBO and try to compute it’s gradient with respect to the parameters of our neural network. Let us recall the expression for ELBO. It is given by,\n$$ \\begin{align*} F_{\\theta}(q_{\\phi}) \u0026= \\mathbb{E}_{q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log \\frac{p_{\\theta}(\\boldsymbol{x}, \\boldsymbol{z})}{q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} \\right] \\\\ \u0026= \\mathbb{E}_{q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log p_{\\theta}(\\boldsymbol{z}, \\boldsymbol{x}) - \\log q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) \\right] \\end{align*} $$\nThe argument of our expectation is a function of both $x$ and $z$. Therefore, we define our ELBO as $\\mathbb{E}_{z \\sim q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} [f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x})]$\n$$ \\begin{align*} \\mathbb{E}_{z \\sim q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} [f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x})] \u0026:= \\mathbb{E}_{z \\sim q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} \\left[\\log p_{\\theta}(\\boldsymbol{z}, \\boldsymbol{x}) - \\log q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) \\right] \\end{align*} $$\nLet us consider the gradient of the ELBO with respect to $\\phi$.\n$$ \\begin{align*} \\nabla_{\\phi} \\mathbb{E}_{z \\sim q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} [f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x})] \u0026= \\nabla_{\\phi} \\int_{\\boldsymbol{z}} q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x}) d\\boldsymbol{z}\\\\ \u0026= \\int_{\\boldsymbol{z}} \\nabla_{\\phi} (q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x})) d\\boldsymbol{z} \\\\ \u0026= \\int_{\\boldsymbol{z}} f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x}) \\nabla_{\\phi} q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) d\\boldsymbol{z} + \\int_{\\boldsymbol{z}} q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) \\nabla_{\\phi} f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x}) d\\boldsymbol{z} \\quad (\\text{product rule}) \\end{align*} $$\nThe first term, which is an integral, is intractable. We cannot write it in the form of an expectation that can be estimated using sample averages (Monte-Carlo estimation).\nThe Reparametrization Trick Fig 2. Updated forward pass with Gaussian reparametrization\nLet us recall that $q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x}) = \\mathcal{N}(z; \\mu_{\\phi}(\\boldsymbol{x}), diag(\\sigma_{1}, \\cdots, \\sigma_{k}))$. We can therefore use the Gaussian reparametrization trick to instead sample from $\\mathcal{N}(0, I)$ and use a deterministic transformation to get a sample from $q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})$.\nTherefore, the sample $z \\sim \\mathcal{N}(z; \\mu_{\\phi}(\\boldsymbol{x}), diag(\\sigma_{1}, \\cdots, \\sigma_{k}))$ is equivalent to,\n$$ \\begin{align*} z \u0026= \\mu_{\\phi}(\\boldsymbol{x}) + \\sigma_{\\phi}(\\boldsymbol{x}) \\odot \\boldsymbol{\\epsilon} \\quad \\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, I) \\\\ \u0026:= g(\\boldsymbol{\\epsilon}; \\phi) \\end{align*} $$\nHere, $\\odot$ denotes element-wise multiplication and $\\sigma_{\\phi}(\\boldsymbol{x}) = [\\sigma_{1}, \\cdots, \\sigma_{k}]^\\top$.\nWe can use the reparametrization trick to make the computation of gradient tractable. We use a simplified notation for $f_{\\theta, \\phi}(\\boldsymbol{z}, \\boldsymbol{x})$, as $f(\\boldsymbol{z}, \\boldsymbol{x})$ to avoid clutter.\n$$ \\begin{align*} \\nabla_{\\phi} \\mathbb{E}_{z \\sim q_{\\phi}(\\boldsymbol{z}|\\boldsymbol{x})} [f(\\boldsymbol{z}, \\boldsymbol{x})] \u0026= \\nabla_{\\phi} \\mathbb{E}_{\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, I)} [f({g(\\boldsymbol{\\epsilon}; \\phi)}, \\boldsymbol{x})] \\\\ \u0026= \\nabla_{\\phi} \\int_{\\boldsymbol{\\epsilon}} \\mathcal{N}(0, I) [f({g(\\boldsymbol{\\epsilon}; \\phi)}, \\boldsymbol{x})] d \\boldsymbol{\\epsilon} \\\\ \u0026= \\int_{\\boldsymbol{\\epsilon}} \\mathcal{N}(0, I) \\nabla_{\\phi} [f({g(\\boldsymbol{\\epsilon}; \\phi)}, \\boldsymbol{x})] d \\boldsymbol{\\epsilon} \\\\ \u0026= \\mathbb{E}_{\\boldsymbol{\\epsilon} \\sim \\mathcal{N}(0, I)} [\\nabla_{\\phi} f({g(\\boldsymbol{\\epsilon}; \\phi)}, \\boldsymbol{x})] \\\\ \u0026\\approx \\frac{1}{N} \\sum_{k=1}^{N} \\nabla_{\\phi} f({g(\\boldsymbol{\\epsilon}_k; \\phi)}, \\boldsymbol{x}) \\end{align*} $$\nCitation Cited as:\nRishab Sharma. (March 2025). Variational Autoencoders and Maximum Likelihood Estimation. https://rish-01.github.io/blog/posts/vae/\nor\n@article{Rishab2025vae, author = \"Rishab Sharma\", title = \"Variational Autoencoders and Maximum Likelihood Estimation\", journal = \"rish-01.github.io/blog\", year = \"2025\", month = \"March\", howpublished = \"https://rish-01.github.io/blog/posts/vae/\", } References [1] Diederik P Kingma, Max Welling. Auto-Encoding Variational Bayes. arXiv preprint arXiv:1312.6114 (2022).\n[2] Stanford CS236: Deep Generative Models I 2023 I Lecture 6 - VAEs. YouTube.\n[3] Lec 9 - Deep Generative Models Variational Auto Encoders. YouTube.\n","wordCount":"1669","inLanguage":"en","image":"http://localhost:1313/blog/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2025-03-06T00:13:00+05:30","dateModified":"2025-03-06T00:13:00+05:30","author":{"@type":"Person","name":"Rishab Sharma"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blog/posts/vae/"},"publisher":{"@type":"Organization","name":"Rish's AI Notes","logo":{"@type":"ImageObject","url":"http://localhost:1313/blog/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/blog/ accesskey=h title="Rish's AI Notes (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Rish's AI Notes</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/blog/archives title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/blog/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/blog/tags/ title=tags><span>tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/blog/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/blog/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Variational Autoencoders and Maximum Likelihood Estimation</h1><div class=post-meta><span title='2025-03-06 00:13:00 +0530 IST'>March 6, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;1669 words&nbsp;·&nbsp;Rishab Sharma&nbsp;|&nbsp;<a href=https://github.com/%3cpath_to_repo%3e/content/posts/vae.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#preliminary-information>Preliminary Information</a><ul><li><a href=#monte-carlo-approximation>Monte Carlo Approximation</a></li><li><a href=#jensens-inequality>Jensen&rsquo;s Inequality</a></li><li><a href=#gaussian-reparametrization>Gaussian Reparametrization</a></li></ul></li><li><a href=#formalizing-the-optimization-problem>Formalizing the Optimization Problem</a></li><li><a href=#deriving-the-evidence-lower-bound-elbo>Deriving the Evidence Lower Bound (ELBO)</a></li><li><a href=#analysis-on-the-variational-posterior-qboldsymbolzboldsymbolx-and-tightness-of-lower-bound>Analysis on the Variational Posterior $q(\boldsymbol{z}|\boldsymbol{x})$ and Tightness of Lower Bound</a></li><li><a href=#modeling-vae-using-neural-networks>Modeling VAE using Neural Networks</a></li><li><a href=#computing-the-gradient-of-the-elbo-for-training>Computing the Gradient of the ELBO for Training</a><ul><li><a href=#the-reparametrization-trick>The Reparametrization Trick</a></li></ul></li><li><a href=#citation>Citation</a></li><li><a href=#references>References</a></li></ul></nav></div></details></div><div class=post-content><p>In my <a href=https://rish-01.github.io/blog/posts/ml_estimation/>previous blog</a>, we explored maximum likelihood estimation (MLE) and how it can be used to derive commonly used loss functions. It also turns out that MLE is widely being used in generative models like Variational Autoencoders (VAE) and Diffusion models (DDPM).</p><p>In this blog, we will explore how the loss function of Variational Autoencoders are derived. VAEs are latent variable generative models. They can solve a few tasks:</p><ol><li>Act as a generative model that mimics the data distribution that it was trained on.</li><li>Approximate posterior inference of the latent variable $z$ given an observed variable $x$. In other words, it can be used to learn lower dimensional representations of the data it was trained on.</li></ol><h2 id=preliminary-information>Preliminary Information<a hidden class=anchor aria-hidden=true href=#preliminary-information>#</a></h2><p>In this section, let us explore the tools necessary to derive a tractable form of the log-likelihood that we need to optimize.</p><h3 id=monte-carlo-approximation>Monte Carlo Approximation<a hidden class=anchor aria-hidden=true href=#monte-carlo-approximation>#</a></h3><p>Let us consider an expectation of a function $f(x)$ with respect to a probability distribution $p(x)$ where $x$ is our random variable.</p><p>$$
\mathbb{E}_{x \sim p(x)} [f(x)] = \int_{x} p(x) f(x) dx
$$</p><p>However, the above integral is intractable if $x$ is higher dimensional. Instead of computing the expectation exactly, we can approximate it using Monte Carlo sampling. If we draw $N$ independent samples $\set{x_{1}, \cdots, x_{N}} \overset{\text{i.i.d.}}{\sim} p(x)$, then the Monte Carlo estimate of the expectation is:</p><p>$$
\mathbb{E}_{x \sim p(x)} [f(x)] \approx \frac{1}{N} \sum_{i=1}^N f(x_i)
$$</p><p>This approximation becomes more accurate as the number of samples $N$ increases, following the law of large numbers.</p><h3 id=jensens-inequality>Jensen&rsquo;s Inequality<a hidden class=anchor aria-hidden=true href=#jensens-inequality>#</a></h3><p>I&rsquo;ve taken a very crude proof for Jensen&rsquo;s inequality from <a href="https://youtu.be/MAGBUh77bNg?si=pOFOYeWTWk2EFXeJ">Deep Generative Models (Stanford)</a>. Let us consider the term $\log \mathbb{E}_{q(\boldsymbol{z})}[f(\boldsymbol{z})]$ and get this in terms of an expectation that is computable with sample averages (Monte-Carlo approximation). We also use the fact that $\log$ is a concave function. From the definition of a concave function, we have the below result for any two points $x$ and $y$ in the domain of $\log(\cdot)$.</p><p>$$
\log(px + (1 - p)y) >= p \log(x) + (1 - p) \log(y) \quad \forall p \in [0, 1] \tag{1}
$$</p><p>We can now use the above result to derive Jensen&rsquo;s inequality. The above result is generalizable to any convex combination of more than two points.</p><p>$$
\begin{align*}
\log \mathbb{E}_{q(\boldsymbol{z})}[f(\boldsymbol{z})] &= \log(\sum_{\boldsymbol{z}} q(\boldsymbol{z})f(\boldsymbol{z})) \\
&>= (\sum_{\boldsymbol{z}} q(\boldsymbol{z}) \log f(\boldsymbol{z})) \quad (\text{from eq. (1)}) \\
&= \mathbb{E}_{q(\boldsymbol{z})}[\log f(\boldsymbol{z})]
\end{align*}
$$</p><h3 id=gaussian-reparametrization>Gaussian Reparametrization<a hidden class=anchor aria-hidden=true href=#gaussian-reparametrization>#</a></h3><p>Let&rsquo;s say we want to sample from a Gaussian distribution $z \sim \mathcal{N}(\mu, \sigma^{2})$. Instead of directly sampling from our Gaussian with an arbitrary mean and variance, we can instead sample from a standard normal distribution $\boldsymbol{\epsilon} \sim \mathcal{N}(0, 1)$ and use a deterministic transformation.</p><p>$$
z = \mu + \sigma \cdot \boldsymbol{\epsilon}, \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0,1)
$$</p><p>It turns out that using the reparametrization trick makes the gradient of our loss function tractable in a VAE.</p><h2 id=formalizing-the-optimization-problem>Formalizing the Optimization Problem<a hidden class=anchor aria-hidden=true href=#formalizing-the-optimization-problem>#</a></h2><p>Consider a dataset of $ m $ images $ \mathbb{X} = \{\mathbf{x^{(1)}}, \dots, \mathbf{x^{(m)}}\} $ where $ \mathbf{x^{(i)}} \in \mathbb{R}^{n \times n} $ is drawn independently (i.i.d) from the true but unknown data generating distribution $ p_{\text{data}}(\boldsymbol{x}) $. Our main goal is to model this distribution using $p_{\theta}(\boldsymbol{x})$ and learn it using data samples.</p><p>Recalling our section on <a href=https://rish-01.github.io/blog/posts/ml_estimation/#what-is-kullback-leibler-kl-divergence>KL-Divergence</a>, our objective can be summarized as:</p><p>$$
L(\theta) = \arg\min_\theta D_{KL}(p_{\text{data}}||p_{\theta})
$$</p><p>We further recall from our <a href=https://rish-01.github.io/blog/posts/ml_estimation/#connecting-mle-to-kl-divergence>previous blog</a> &ndash; the connection between minimizing KL-Divergence and maximizing the likelihood. Our optimization problem then converts to maximizing the log-likelihood.</p><p>$$
\begin{align*}
L(\theta) &= \arg\min_\theta \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\boldsymbol{x})} \left[ \log \frac{p_{\text{data}}(\boldsymbol{x})}{p_{\theta}(\boldsymbol{x})} \right] \\
&= \arg\min_\theta \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\boldsymbol{x})} \left[ \log p_{\text{data}}(\boldsymbol{x}) - \log p_{\theta}(\boldsymbol{x}) \right] \\
&= \arg\min_\theta \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\boldsymbol{x})} \left[ \log p_{\text{data}}(\boldsymbol{x}) \right] - \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}} \left[ \log p_{\theta}(\boldsymbol{x}) \right] \\
&= \arg\max_\theta \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}(\boldsymbol{x})} \left[ \log p_{\theta}(\boldsymbol{x}) \right] \quad (\because \text{First term is independent of } \theta) \\
&= \arg\max_\theta \frac{1}{N} \sum_{i=1}^N \log p_{\theta}(x_i) \quad (\text{Monte-Carlo estimation})
\end{align*}
$$</p><h2 id=deriving-the-evidence-lower-bound-elbo>Deriving the Evidence Lower Bound (ELBO)<a hidden class=anchor aria-hidden=true href=#deriving-the-evidence-lower-bound-elbo>#</a></h2><p>Let us consider the term $p_{\theta}(\boldsymbol{x})$. Since $p_{\theta}(\boldsymbol{x})$ is a latent variable model, it can be written as,</p><p>$$
p_{\theta}(\boldsymbol{x}) = \int p_{\theta}(\boldsymbol{x}, \boldsymbol{z}) d\boldsymbol{z} \tag{2}
$$</p><p>The above equation is just the marginalization of the joint distribution $p_{\theta}(\boldsymbol{x}, \boldsymbol{z})$. We are interested in computing $\log p_{\theta}(\boldsymbol{x})$. Our main goal is to write the log-likelihood function in terms of an expectation which is computable.</p><p>$$
\begin{align*}
\log p_{\theta}(\boldsymbol{x}) &= \log \int_{\boldsymbol{z}} p_{\theta}(\boldsymbol{x}, \boldsymbol{z}) d\boldsymbol{z} \\
&= \log \int_{\boldsymbol{z}} \frac{p_{\theta}(\boldsymbol{x}, \boldsymbol{z})}{q(\boldsymbol{z} | \boldsymbol{x})} q(\boldsymbol{z}|\boldsymbol{x}) d\boldsymbol{z} \\
&= \log \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[ \frac{p_{\theta}(\boldsymbol{x}, \boldsymbol{z})}{q(\boldsymbol{z}|\boldsymbol{x})} \right] \\
&>= \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{p_{\theta}(\boldsymbol{x}, \boldsymbol{z})}{q(\boldsymbol{z}|\boldsymbol{x})} \right] \quad (\text{From Jensen&rsquo;s inequality}) \\
&= \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{p_{\theta}(\boldsymbol{x}|\boldsymbol{z}) p_{\theta}(\boldsymbol{z})}{q(\boldsymbol{z} |\boldsymbol{x})} \right] \\
&= \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log p_{\theta}(\boldsymbol{x}|\boldsymbol{z}) \right] - \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{q(\boldsymbol{z}|\boldsymbol{x})}{p_{\theta}(\boldsymbol{z})} \right] \\
&= \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log p_{\theta}(\boldsymbol{x}|\boldsymbol{z}) \right] - D_{KL}(q(\boldsymbol{z}|\boldsymbol{x}) || p_{\theta}(\boldsymbol{z})) \\
&:= F_{\theta}(q)
\end{align*}
$$</p><p>We have derived a tractable lower bound $F_{\theta}(q)$ (ELBO) for log-likelihood that we can maximize. The tightness of this lower bound depends on the choice of $q(\boldsymbol{z}|\boldsymbol{x})$ (variational posterior).</p><h2 id=analysis-on-the-variational-posterior-qboldsymbolzboldsymbolx-and-tightness-of-lower-bound>Analysis on the Variational Posterior $q(\boldsymbol{z}|\boldsymbol{x})$ and Tightness of Lower Bound<a hidden class=anchor aria-hidden=true href=#analysis-on-the-variational-posterior-qboldsymbolzboldsymbolx-and-tightness-of-lower-bound>#</a></h2><p>Let us consider the term $(\log p_{\theta}(\boldsymbol{x}) - F_{\theta}(q))$. To have a tight lower bound, we need to choose a $q$ that minimizes this difference.</p><p>$$
\begin{align*}
\log p_{\theta}(\boldsymbol{x}) - F_{\theta}(q) &= \log p_{\theta}(\boldsymbol{x}) - \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{p_{\theta}(\boldsymbol{x}, \boldsymbol{z})}{q(\boldsymbol{z}|\boldsymbol{x})} \right] \\
&= \log p_{\theta}(\boldsymbol{x}) - \mathbb{E}_{q(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x}) p_{\theta}(\boldsymbol{x})}{q(\boldsymbol{z} |\boldsymbol{x})} \right] \\
&= \log p_{\theta}(\boldsymbol{x}) - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x}) p_{\theta}(\boldsymbol{x})}{q(\boldsymbol{z} |\boldsymbol{x})} \right) d\boldsymbol{z} \\
&= \log p_{\theta}(\boldsymbol{x}) - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log p_{\theta}(\boldsymbol{x}) d\boldsymbol{z} - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x})}{{q(\boldsymbol{z} |\boldsymbol{x})}} \right) d\boldsymbol{z} \\
&= \log p_{\theta}(\boldsymbol{x}) - \log p_{\theta}(\boldsymbol{x}) \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) d\boldsymbol{z} - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x})}{{q(\boldsymbol{z} |\boldsymbol{x})}} \right) d\boldsymbol{z} \\
&= \cancel{\log p_{\theta}(\boldsymbol{x})} - \cancel{\log p_{\theta}(\boldsymbol{x})} - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x})}{{q(\boldsymbol{z} |\boldsymbol{x})}} \right) d\boldsymbol{z} \quad (\because \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) d\boldsymbol{z} = 1)\\
&= - \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{p_{\theta}(\boldsymbol{z}|\boldsymbol{x})}{{q(\boldsymbol{z} |\boldsymbol{x})}} \right) d\boldsymbol{z} \\
&= \int_{\boldsymbol{z}} q(\boldsymbol{z} |\boldsymbol{x}) \log \left(\frac{{q(\boldsymbol{z} |\boldsymbol{x})}}{p_{\theta}(\boldsymbol{z}|\boldsymbol{x})} \right) d\boldsymbol{z} \\
&= D_{KL}(q(\boldsymbol{z} |\boldsymbol{x}) || p_{\theta}(\boldsymbol{z}|\boldsymbol{x}))
\end{align*}
$$</p><p>We have therefore proved that the error from the lower bound is,</p><p>$$
\log p_{\theta}(\boldsymbol{x}) - F_{\theta}(q) = D_{KL}(q(\boldsymbol{z} |\boldsymbol{x}) || p_{\theta}(\boldsymbol{z}|\boldsymbol{x}))
$$</p><p>We can find the optimal value for $q(\boldsymbol{z} |\boldsymbol{x})$ by setting this error to zero.</p><p>$$
D_{KL}(q(\boldsymbol{z} |\boldsymbol{x}) || p_{\theta}(\boldsymbol{z}|\boldsymbol{x})) = 0
$$</p><p>Therefore, the optimal value of $q(\boldsymbol{z} |\boldsymbol{x})$ is $p_{\theta}(\boldsymbol{z}|\boldsymbol{x})$ where the lower bound is known to be the tightest. However, $p_{\theta}(\boldsymbol{z}|\boldsymbol{x})$ is not tractable in VAEs which is why we explore alternate forms for $q(\boldsymbol{z} |\boldsymbol{x})$.</p><h2 id=modeling-vae-using-neural-networks>Modeling VAE using Neural Networks<a hidden class=anchor aria-hidden=true href=#modeling-vae-using-neural-networks>#</a></h2><figure class=align-center><img loading=lazy src=/blog/images/vae/Variational_Autoencoder.png#center><figcaption><p>Fig 1. Variational Autoencoder</p></figcaption></figure><p>In a VAE, $q(\boldsymbol{z}|\boldsymbol{x})$ is modeled using a stochastic neural network with parameters $\phi$. We assume a Gaussian form for $q(\boldsymbol{z}|\boldsymbol{x})$ for mathematical convenience. Therefore, the encoder can be used to predict the parameters of our Gaussian distribution.</p><p>$$
q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) = \mathcal{N}(z; \mu_{\phi}(\boldsymbol{x}), \Sigma_{\phi}(\boldsymbol{x}))
$$</p><p>We also assume a diagonal form for the covariance matrix $\Sigma_{\phi}(\boldsymbol{x}) = diag(\sigma_{1}, \cdots, \sigma_{k})$ for further convenience.</p><p>$$
\therefore q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) = \mathcal{N}(z; \mu_{\phi}(\boldsymbol{x}), diag(\sigma_{1}, \cdots, \sigma_{k}))
$$</p><p>Here, our latent variable $\boldsymbol{z} \in \mathbb{R}^k$ and $D = \set{\boldsymbol{x_i}}_{i=1}^n \sim p_{\text{data}}$ where $x_i \in \mathbb{R}^d \quad \forall i \in \set{1, \cdots, n}$. Since our latent variable is $k$-dimensional, $\mu(\boldsymbol{x}) \in \mathbb{R}^k$, and $ [\sigma_1, \cdots, \sigma_k]^\top \in \mathbb{R}^k $. Our encoder therefore maps our input to $\mathbb{R}^{2k}$ dimensional space to estimate the parameters of our Gaussian distribution, $\mu(\boldsymbol{x})$, and $diag(\sigma_1, \cdots, \sigma_k)$.</p><h2 id=computing-the-gradient-of-the-elbo-for-training>Computing the Gradient of the ELBO for Training<a hidden class=anchor aria-hidden=true href=#computing-the-gradient-of-the-elbo-for-training>#</a></h2><p>Let us go back to the ELBO and try to compute it&rsquo;s gradient with respect to the parameters of our neural network. Let us recall the expression for ELBO. It is given by,</p><p>$$
\begin{align*}
F_{\theta}(q_{\phi}) &= \mathbb{E}_{q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} \left[\log \frac{p_{\theta}(\boldsymbol{x}, \boldsymbol{z})}{q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} \right] \\
&= \mathbb{E}_{q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} \left[\log p_{\theta}(\boldsymbol{z}, \boldsymbol{x}) - \log q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) \right]
\end{align*}
$$</p><p>The argument of our expectation is a function of both $x$ and $z$. Therefore, we define our ELBO as $\mathbb{E}_{z \sim q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} [f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x})]$</p><p>$$
\begin{align*}
\mathbb{E}_{z \sim q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} [f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x})] &:= \mathbb{E}_{z \sim q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} \left[\log p_{\theta}(\boldsymbol{z}, \boldsymbol{x}) - \log q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) \right]
\end{align*}
$$</p><p>Let us consider the gradient of the ELBO with respect to $\phi$.</p><p>$$
\begin{align*}
\nabla_{\phi} \mathbb{E}_{z \sim q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} [f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x})] &= \nabla_{\phi} \int_{\boldsymbol{z}} q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x}) d\boldsymbol{z}\\
&= \int_{\boldsymbol{z}} \nabla_{\phi} (q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x})) d\boldsymbol{z} \\
&= \int_{\boldsymbol{z}} f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x}) \nabla_{\phi} q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) d\boldsymbol{z} + \int_{\boldsymbol{z}} q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) \nabla_{\phi} f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x}) d\boldsymbol{z} \quad (\text{product rule})
\end{align*}
$$</p><p>The first term, which is an integral, is intractable. We cannot write it in the form of an expectation that can be estimated using sample averages (Monte-Carlo estimation).</p><h3 id=the-reparametrization-trick>The Reparametrization Trick<a hidden class=anchor aria-hidden=true href=#the-reparametrization-trick>#</a></h3><figure class=align-center><img loading=lazy src=/blog/images/vae/Reparametrization.png#center><figcaption><p>Fig 2. Updated forward pass with Gaussian reparametrization</p></figcaption></figure><p>Let us recall that $q_{\phi}(\boldsymbol{z}|\boldsymbol{x}) = \mathcal{N}(z; \mu_{\phi}(\boldsymbol{x}), diag(\sigma_{1}, \cdots, \sigma_{k}))$. We can therefore use the Gaussian reparametrization trick to instead sample from $\mathcal{N}(0, I)$ and use a deterministic transformation to get a sample from $q_{\phi}(\boldsymbol{z}|\boldsymbol{x})$.</p><p>Therefore, the sample $z \sim \mathcal{N}(z; \mu_{\phi}(\boldsymbol{x}), diag(\sigma_{1}, \cdots, \sigma_{k}))$ is equivalent to,</p><p>$$
\begin{align*}
z &= \mu_{\phi}(\boldsymbol{x}) + \sigma_{\phi}(\boldsymbol{x}) \odot \boldsymbol{\epsilon} \quad \boldsymbol{\epsilon} \sim \mathcal{N}(0, I) \\
&:= g(\boldsymbol{\epsilon}; \phi)
\end{align*}
$$</p><p>Here, $\odot$ denotes element-wise multiplication and $\sigma_{\phi}(\boldsymbol{x}) = [\sigma_{1}, \cdots, \sigma_{k}]^\top$.</p><p>We can use the reparametrization trick to make the computation of gradient tractable. We use a simplified notation for $f_{\theta, \phi}(\boldsymbol{z}, \boldsymbol{x})$, as $f(\boldsymbol{z}, \boldsymbol{x})$ to avoid clutter.</p><p>$$
\begin{align*}
\nabla_{\phi} \mathbb{E}_{z \sim q_{\phi}(\boldsymbol{z}|\boldsymbol{x})} [f(\boldsymbol{z}, \boldsymbol{x})] &= \nabla_{\phi} \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)} [f({g(\boldsymbol{\epsilon}; \phi)}, \boldsymbol{x})] \\
&= \nabla_{\phi} \int_{\boldsymbol{\epsilon}} \mathcal{N}(0, I) [f({g(\boldsymbol{\epsilon}; \phi)}, \boldsymbol{x})] d \boldsymbol{\epsilon} \\
&= \int_{\boldsymbol{\epsilon}} \mathcal{N}(0, I) \nabla_{\phi} [f({g(\boldsymbol{\epsilon}; \phi)}, \boldsymbol{x})] d \boldsymbol{\epsilon} \\
&= \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)} [\nabla_{\phi} f({g(\boldsymbol{\epsilon}; \phi)}, \boldsymbol{x})] \\
&\approx \frac{1}{N} \sum_{k=1}^{N} \nabla_{\phi} f({g(\boldsymbol{\epsilon}_k; \phi)}, \boldsymbol{x})
\end{align*}
$$</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><p>Cited as:</p><blockquote><p>Rishab Sharma. (March 2025). Variational Autoencoders and Maximum Likelihood Estimation. <a href=https://rish-01.github.io/blog/posts/vae/>https://rish-01.github.io/blog/posts/vae/</a></p></blockquote><p>or</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl><span class=nc>@article</span><span class=p>{</span><span class=nl>Rishab2025vae</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>author</span>       <span class=p>=</span> <span class=s>&#34;Rishab Sharma&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>title</span>        <span class=p>=</span> <span class=s>&#34;Variational Autoencoders and Maximum Likelihood Estimation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>journal</span>      <span class=p>=</span> <span class=s>&#34;rish-01.github.io/blog&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>year</span>         <span class=p>=</span> <span class=s>&#34;2025&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>month</span>        <span class=p>=</span> <span class=s>&#34;March&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=na>howpublished</span> <span class=p>=</span> <span class=s>&#34;https://rish-01.github.io/blog/posts/vae/&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><p>[1] Diederik P Kingma, Max Welling. <a href=https://arxiv.org/abs/1312.6114>Auto-Encoding Variational Bayes</a>. arXiv preprint arXiv:1312.6114 (2022).</p><p>[2] <a href="https://youtu.be/8cO61e_8oPY?si=4YgMVYen2O0MSz9o">Stanford CS236: Deep Generative Models I 2023 I Lecture 6 - VAEs</a>. YouTube.</p><p>[3] <a href="https://youtu.be/c475SLygCK4?si=sIGn-DPwT2LgEMoy">Lec 9 - Deep Generative Models Variational Auto Encoders</a>. YouTube.</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/blog/tags/ml-estimation/>ML Estimation</a></li><li><a href=http://localhost:1313/blog/tags/kl-divergence/>KL Divergence</a></li><li><a href=http://localhost:1313/blog/tags/evidence-lower-bound/>Evidence Lower Bound</a></li><li><a href=http://localhost:1313/blog/tags/variational-autoencoders/>Variational Autoencoders</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/blog/posts/ml_estimation/><span class=title>Next »</span><br><span>Maximum Likelihood Estimation and Loss Functions</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on x" href="https://x.com/intent/tweet/?text=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f&amp;hashtags=MLEstimation%2cKLDivergence%2cEvidenceLowerBound%2cVariationalAutoencoders"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f&amp;title=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation&amp;summary=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation&amp;source=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f&title=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on whatsapp" href="https://api.whatsapp.com/send?text=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation%20-%20http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on telegram" href="https://telegram.me/share/url?text=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation&amp;url=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Variational Autoencoders and Maximum Likelihood Estimation on ycombinator" href="https://news.ycombinator.com/submitlink?t=Variational%20Autoencoders%20and%20Maximum%20Likelihood%20Estimation&u=http%3a%2f%2flocalhost%3a1313%2fblog%2fposts%2fvae%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/blog/>Rish's AI Notes</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>